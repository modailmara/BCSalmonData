{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## This Notebook integrates all the wild data sources.\n",
    "### This includes our data from a variety of sources, as well as data from Salmon Coast Field Station, Cedar Creek Field Station, and the Hakai Institute"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration variables for this notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "# paths to files for our data\n",
    "wild_data_dir = Path('.')\n",
    "events_filepath = wild_data_dir / 'wild_sample_events.csv'\n",
    "fish_lice_filepath = wild_data_dir / 'wild_fish_lice.csv'\n",
    "\n",
    "# paths to the Salmon Coast Field Station data files\n",
    "scfs_events_filepath = wild_data_dir / 'salmon_coast_wild_sample_events.csv'\n",
    "scfs_fish_lice_filepath = wild_data_dir / 'salmon_coast_wild_fish_lice.csv'\n",
    "\n",
    "# paths to the Cedar Creek Field Station data files\n",
    "ccfs_events_filepath = wild_data_dir / 'cedar_coast_wild_sample_events.csv'\n",
    "ccfs_fish_lice_filepath = wild_data_dir / 'cedar_coast_wild_fish_lice.csv'\n",
    "\n",
    "# paths to the Hakai Institute data files\n",
    "hakai_events_filepath = wild_data_dir / 'hakai_wild_sample_events.csv'\n",
    "hakai_fish_lice_filepath = wild_data_dir / 'hakai_wild_fish_lice.csv'\n",
    "\n",
    "# output paths for writing the combined data\n",
    "all_events_filepath = wild_data_dir / 'all_wild_sample_events.csv'\n",
    "all_fish_lice_filepath = wild_data_dir / 'all_wild_fish_lice.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Join all the event data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# load the event data files\n",
    "events_df = pd.read_csv(events_filepath)\n",
    "scfs_events_df = pd.read_csv(scfs_events_filepath)\n",
    "ccfs_events_df = pd.read_csv(ccfs_events_filepath)\n",
    "hakai_events_df = pd.read_csv(hakai_events_filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "  event_id  sampledate                 region dfozone   sample_site  latitude  \\\n0        1  2003-05-13  Broughton Archipelago     3_3  Adeane Point  50.71978   \n1        2  2003-05-21  Broughton Archipelago     3_3  Adeane Point  50.71978   \n2        3  2003-05-26  Broughton Archipelago     3_3  Adeane Point   50.7197   \n3        4  2003-06-02  Broughton Archipelago     3_3  Adeane Point   50.7197   \n4        5  2003-05-13  Broughton Archipelago     3_3  Adeane Point   50.7384   \n\n   longitude                       source  \n0 -125.67950  Fisheries and Oceans Canada  \n1 -125.67950  Fisheries and Oceans Canada  \n2 -125.67950  Fisheries and Oceans Canada  \n3 -125.67950  Fisheries and Oceans Canada  \n4 -125.67985  Fisheries and Oceans Canada  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_id</th>\n      <th>sampledate</th>\n      <th>region</th>\n      <th>dfozone</th>\n      <th>sample_site</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2003-05-13</td>\n      <td>Broughton Archipelago</td>\n      <td>3_3</td>\n      <td>Adeane Point</td>\n      <td>50.71978</td>\n      <td>-125.67950</td>\n      <td>Fisheries and Oceans Canada</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2003-05-21</td>\n      <td>Broughton Archipelago</td>\n      <td>3_3</td>\n      <td>Adeane Point</td>\n      <td>50.71978</td>\n      <td>-125.67950</td>\n      <td>Fisheries and Oceans Canada</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2003-05-26</td>\n      <td>Broughton Archipelago</td>\n      <td>3_3</td>\n      <td>Adeane Point</td>\n      <td>50.7197</td>\n      <td>-125.67950</td>\n      <td>Fisheries and Oceans Canada</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2003-06-02</td>\n      <td>Broughton Archipelago</td>\n      <td>3_3</td>\n      <td>Adeane Point</td>\n      <td>50.7197</td>\n      <td>-125.67950</td>\n      <td>Fisheries and Oceans Canada</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2003-05-13</td>\n      <td>Broughton Archipelago</td>\n      <td>3_3</td>\n      <td>Adeane Point</td>\n      <td>50.7384</td>\n      <td>-125.67985</td>\n      <td>Fisheries and Oceans Canada</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all the files\n",
    "all_events_df = pd.concat([events_df, scfs_events_df, ccfs_events_df, hakai_events_df], ignore_index=True, sort=False)\n",
    "all_events_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# write out to CSV\n",
    "all_events_df.to_csv(all_events_filepath, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Join all the fish/lice data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# load the fish/lice files\n",
    "fish_lice_df = pd.read_csv(fish_lice_filepath)\n",
    "scfs_fish_lice_df = pd.read_csv(scfs_fish_lice_filepath)\n",
    "ccfs_fish_lice_df = pd.read_csv(ccfs_events_filepath)\n",
    "hakai_fish_lice_df = pd.read_csv(hakai_fish_lice_filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "  event_id fish_id  length  weight  height fish_species  lep_cop  lep_chal  \\\n0     5666       1    44.0    0.96     NaN  Chum Salmon      1.0       0.0   \n1     5666       2    39.0    0.61     NaN  Pink Salmon      0.0       1.0   \n2     5666       3    45.0    0.94     NaN  Pink Salmon      0.0       0.0   \n3     5666       4    43.0    0.84     NaN  Chum Salmon      0.0       0.0   \n4     5666       5    38.0    0.53     NaN  Pink Salmon      0.0       0.0   \n\n   lep_motile  lep_unknown  ...  unknown_motile  unknown_unknown  sampledate  \\\n0         0.0          0.0  ...             0.0              0.0         NaN   \n1         0.0          0.0  ...             0.0              0.0         NaN   \n2         0.0          0.0  ...             0.0              0.0         NaN   \n3         0.0          0.0  ...             0.0              0.0         NaN   \n4         0.0          0.0  ...             0.0              0.0         NaN   \n\n   region  dfozone  sample_site  latitude  longitude source lice_protocol  \n0     NaN      NaN          NaN       NaN        NaN    NaN           NaN  \n1     NaN      NaN          NaN       NaN        NaN    NaN           NaN  \n2     NaN      NaN          NaN       NaN        NaN    NaN           NaN  \n3     NaN      NaN          NaN       NaN        NaN    NaN           NaN  \n4     NaN      NaN          NaN       NaN        NaN    NaN           NaN  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_id</th>\n      <th>fish_id</th>\n      <th>length</th>\n      <th>weight</th>\n      <th>height</th>\n      <th>fish_species</th>\n      <th>lep_cop</th>\n      <th>lep_chal</th>\n      <th>lep_motile</th>\n      <th>lep_unknown</th>\n      <th>...</th>\n      <th>unknown_motile</th>\n      <th>unknown_unknown</th>\n      <th>sampledate</th>\n      <th>region</th>\n      <th>dfozone</th>\n      <th>sample_site</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>source</th>\n      <th>lice_protocol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5666</td>\n      <td>1</td>\n      <td>44.0</td>\n      <td>0.96</td>\n      <td>NaN</td>\n      <td>Chum Salmon</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5666</td>\n      <td>2</td>\n      <td>39.0</td>\n      <td>0.61</td>\n      <td>NaN</td>\n      <td>Pink Salmon</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5666</td>\n      <td>3</td>\n      <td>45.0</td>\n      <td>0.94</td>\n      <td>NaN</td>\n      <td>Pink Salmon</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5666</td>\n      <td>4</td>\n      <td>43.0</td>\n      <td>0.84</td>\n      <td>NaN</td>\n      <td>Chum Salmon</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5666</td>\n      <td>5</td>\n      <td>38.0</td>\n      <td>0.53</td>\n      <td>NaN</td>\n      <td>Pink Salmon</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 26 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all the files\n",
    "all_fish_lice_df = pd.concat([fish_lice_df, scfs_fish_lice_df, ccfs_fish_lice_df, hakai_fish_lice_df],\n",
    "                             ignore_index=True, sort=False)\n",
    "all_fish_lice_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# write out to csv\n",
    "all_fish_lice_df.to_csv(all_fish_lice_filepath, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}